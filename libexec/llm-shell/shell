#!/usr/bin/env ruby
# frozen_string_literal: true

def main(argv)
  if argv.include?("-v") || argv.include?("--version")
    puts LLM::Shell::VERSION
  else
    options = {tools: []}
    option_parser.parse(argv, into: options)
    if argv.empty? || options[:provider].nil?
      warn option_parser.help
      throw(:exit, 1)
    else
      LLM::Shell.new(options).start
    end
  end
end

def option_parser
  OptionParser.new do |o|
    o.banner = "Usage: llm-shell [OPTIONS]"
    o.on("-p PROVIDER", "--provider NAME", "Required. Options: gemini, openai, anthropic, ollama or llamacpp.", String)
    o.on("-k [KEY]", "--key [KEY]", "Optional. Required by gemini, openai, and anthropic.", String)
    o.on("-m [MODEL]", "--model [MODEL]", "Optional. The name of a model.", Array)
    o.on("-h [HOST]", "--host [HOST]", "Optional. Sometimes required by ollama.", String)
    o.on("-o [PORT]", "--port [PORT]", "Optional. Sometimes required by ollama.", Integer)
    o.on("-r [PROMPT]", "--prompt [PROMPT]", "Optional. The prompt to use.", String)
    o.on("-v", "--version", "Optional. Print the version and exit.")
  end
end

excode = catch(:exit) do
  require_relative "../../lib/llm/shell"
  main(ARGV)
  throw(:exit, 0)
rescue => ex
  print Paint[ex.class, :red, :bold], "\n"
  print ex.message, "\n\n"
  print Paint["Backtrace", :bold], "\n"
  print ex.backtrace[0..7].join("\n"), "\n"
  throw(:exit, 1)
end
exit excode
